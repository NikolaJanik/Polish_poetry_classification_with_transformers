{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMvX3uQi9Hq5XH0tZ9L0oXm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NikolaJanik/Polish_poetry_classification_with_transformers/blob/main/ML_and_NN_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Install dependencies (for Google Colab)"
      ],
      "metadata": {
        "id": "l4cNjZhfbzfa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers sacremoses --quiet\n",
        "!pip install xgboost lightgbm --quiet"
      ],
      "metadata": {
        "id": "CVT1VmO5bwOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Imports"
      ],
      "metadata": {
        "id": "0k90f2_6buBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from transformers import HerbertTokenizer, RobertaModel"
      ],
      "metadata": {
        "id": "Bgh6HWdBbrYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Load and prepare data\n"
      ],
      "metadata": {
        "id": "kA9RMcSWboZb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_raw = pd.read_csv('/content/polish_poetry.csv', sep=';')\n",
        "\n",
        "# Usuwamy zbędne kolumny\n",
        "drop_cols = [col for col in df_raw.columns if 'Unnamed' in col]\n",
        "df_raw = df_raw.drop(columns=drop_cols)\n",
        "\n",
        "print(\"Liczba wierszy:\", df_raw.shape[0])\n",
        "print(\"Klasy:\", df_raw['Label'].nunique())"
      ],
      "metadata": {
        "id": "eu8TrOMIbl11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Tokenization and embedding function"
      ],
      "metadata": {
        "id": "Mm5PgWshbjyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_embedding(df, model_info):\n",
        "    model_name, tokenizer, model = model_info\n",
        "    embeddings = []\n",
        "    labels = []\n",
        "\n",
        "    for text, label in tqdm(zip(df['Text'], df['Label']), total=len(df)):\n",
        "        inputs = tokenizer(\n",
        "            text,\n",
        "            max_length=512,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        outputs = model(**inputs)\n",
        "        vector = outputs.last_hidden_state[:, 0, :].detach().numpy()[0]\n",
        "        embeddings.append(vector)\n",
        "        labels.append(label)\n",
        "\n",
        "    return pd.DataFrame({\n",
        "        f\"{model_name}_embedding\": embeddings,\n",
        "        \"label\": labels\n",
        "    })"
      ],
      "metadata": {
        "id": "oYuJMVKYbg7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. HerBERT initialization"
      ],
      "metadata": {
        "id": "oDgyvP1Vbfb2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_embedded = make_embedding(df_raw, herbert)\n",
        "df_embedded = df_embedded.sample(frac=1).reset_index(drop=Tru"
      ],
      "metadata": {
        "id": "J-Qum4YdbdNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Prepare X and y sets"
      ],
      "metadata": {
        "id": "iElwaJvHbcNM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_splits(df, embed_col, test_size=0.2, val_size=0.2):\n",
        "    X = np.stack(df[embed_col])\n",
        "    y = df['label']\n",
        "\n",
        "    # Jeżeli mniej niż 8 klas, zamieniamy etykiety na kategorie 0...n-1\n",
        "    if len(np.unique(y)) < 8:\n",
        "        y = pd.factorize(y)[0]\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, stratify=y)\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=val_size, stratify=y_train)\n",
        "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
        "\n",
        "X_train, X_val, X_test, y_train, y_val, y_test = get_splits(df_embedded, 'Herbert_embedding')\n"
      ],
      "metadata": {
        "id": "warB-uN7bVok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Machine learning model (Decision Tree)"
      ],
      "metadata": {
        "id": "pMaIqD6SbT1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_ml_model(X_train, y_train, X_test, y_test, model, model_name):\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    cm = confusion_matrix(y_test, y_pred, normalize='true')\n",
        "\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "    disp.plot(xticks_rotation=45)\n",
        "    plt.title(f\"{model_name} | Accuracy: {acc:.2f}\")\n",
        "    plt.show()\n",
        "    return acc, cm\n",
        "\n",
        "tree_acc, tree_cm = run_ml_model(\n",
        "    X_train, y_train, X_test, y_test,\n",
        "    DecisionTreeClassifier(max_depth=20),\n",
        "    \"Decision Tree\"\n",
        ")"
      ],
      "metadata": {
        "id": "rz1yLW0dbQiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. Neural network model"
      ],
      "metadata": {
        "id": "bNKQ20UlbPaY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = X_train.shape[1]\n",
        "num_classes = len(np.unique(y_train))\n",
        "\n",
        "y_train_cat = to_categorical(y_train, num_classes)\n",
        "y_val_cat = to_categorical(y_val, num_classes)\n",
        "\n",
        "model_NN = Sequential([\n",
        "    Dense(input_size, activation='relu', input_shape=(input_size,)),\n",
        "    Dense(2 * input_size, activation='relu'),\n",
        "    Dense(4 * input_size, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model_NN.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "history = model_NN.fit(\n",
        "    X_train, y_train_cat,\n",
        "    validation_data=(X_val, y_val_cat),\n",
        "    epochs=50,\n",
        "    batch_size=64,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "oQWE0NwIbJoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. Learning rate curve"
      ],
      "metadata": {
        "id": "0JKiAYkCbHB2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_learning_curve(history):\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "    axs[0].plot(history.history['accuracy'], label='train')\n",
        "    axs[0].plot(history.history['val_accuracy'], label='val')\n",
        "    axs[0].set_title(\"Accuracy\")\n",
        "    axs[0].legend()\n",
        "\n",
        "    axs[1].plot(history.history['loss'], label='train')\n",
        "    axs[1].plot(history.history['val_loss'], label='val')\n",
        "    axs[1].set_title(\"Loss\")\n",
        "    axs[1].legend()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "plot_learning_curve(history)"
      ],
      "metadata": {
        "id": "puSVuZ0hbEce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 11. Neural network confusion matrix"
      ],
      "metadata": {
        "id": "lGpUNnDebCNE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PabJ5wLEa24X"
      },
      "outputs": [],
      "source": [
        "y_pred_nn = np.argmax(model_NN.predict(X_test), axis=1)\n",
        "nn_acc = accuracy_score(y_test, y_pred_nn)\n",
        "nn_cm = confusion_matrix(y_test, y_pred_nn, normalize='true')\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=nn_cm)\n",
        "disp.plot(xticks_rotation=45)\n",
        "plt.title(f\"Neural Network | Accuracy: {nn_acc:.2f}\")\n",
        "plt.show()"
      ]
    }
  ]
}
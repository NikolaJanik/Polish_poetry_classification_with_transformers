{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NikolaJanik/Polish_poetry_classification_with_transformers/blob/main/cosine_distance_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f28f1b2f",
      "metadata": {
        "id": "f28f1b2f"
      },
      "source": [
        "# Polish Poetry Author Classification – Cosine and Euclidean Distance Based Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Install necessary packages"
      ],
      "metadata": {
        "id": "t52E0TZ4Qwo_"
      },
      "id": "t52E0TZ4Qwo_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c5512bb",
      "metadata": {
        "id": "2c5512bb"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install sacremoses"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Imports"
      ],
      "metadata": {
        "id": "6debdM9NQ37K"
      },
      "id": "6debdM9NQ37K"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1aebed7",
      "metadata": {
        "id": "f1aebed7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from transformers import HerbertTokenizer, RobertaModel"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Load HerBERT model and tokenizer"
      ],
      "metadata": {
        "id": "2kfEoFddQ8vt"
      },
      "id": "2kfEoFddQ8vt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "115e7cb8",
      "metadata": {
        "id": "115e7cb8"
      },
      "outputs": [],
      "source": [
        "herbert_klej = [\n",
        "    \"Herbert-klej\",\n",
        "    HerbertTokenizer.from_pretrained(\"allegro/herbert-klej-cased-tokenizer-v1\"),\n",
        "    RobertaModel.from_pretrained(\"allegro/herbert-klej-cased-v1\")\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Load dataset"
      ],
      "metadata": {
        "id": "uIXk5cJrRJfj"
      },
      "id": "uIXk5cJrRJfj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72dc663c",
      "metadata": {
        "id": "72dc663c"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Adjust path as needed\n",
        "df_raw = pd.read_csv('/content/wiersze_do_BERT_Herbert_Miłosz.csv', sep=';')\n",
        "df_raw = df_raw.drop(columns=['Unnamed: 9', 'Unnamed: 10', 'Unnamed: 11'])\n",
        "\n",
        "# Keep only first 400 examples (200 male, 200 female)\n",
        "df_raw = df_raw.iloc[:400]\n",
        "\n",
        "# Split into male and female authors\n",
        "df_women = df_raw[200:].reset_index(drop=True).sample(frac=1).reset_index(drop=True)\n",
        "df_men = df_raw[:200].reset_index(drop=True).sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# Prepare full dataframe\n",
        "df_orginal = pd.concat([df_raw[\"Text\"], df_raw[\"Label\"], df_raw[\"Author-short\"]], axis=1)\n",
        "df_orginal = df_orginal.sample(frac=1).reset_index(drop=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Define functions"
      ],
      "metadata": {
        "id": "3TsV5CHlRYu7"
      },
      "id": "3TsV5CHlRYu7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22dd2c33",
      "metadata": {
        "id": "22dd2c33"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Embedding generation using CLS token\n",
        "def make_embedding(df, model):\n",
        "    _, tokenizer, model = model\n",
        "    embedded = {}\n",
        "    for idx in tqdm(range(len(df))):\n",
        "        text = df['Text'][idx]\n",
        "        inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
        "        outputs = model(**inputs)\n",
        "        cls_embedding = outputs[0][:, 0, :].detach().numpy()[0]\n",
        "        embedded[idx] = (cls_embedding, df['Label'][idx])\n",
        "    return pd.DataFrame.from_dict(embedded, orient='index', columns=['embedding', 'label'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73f781f8",
      "metadata": {
        "id": "73f781f8"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Normalize embeddings per sample\n",
        "def normalize_data(X):\n",
        "    return (X - np.mean(X, axis=1, keepdims=True)) / np.std(X, axis=1, keepdims=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e3a3b7f",
      "metadata": {
        "id": "6e3a3b7f"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Split data into train, val, test\n",
        "def get_X_y_train(df, normalization=True):\n",
        "    X = np.stack(df['embedding'])\n",
        "    y = df['label'].factorize()[0]\n",
        "    if normalization:\n",
        "        X = normalize_data(X)\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
        "    return X, y, X_train, X_val, y_train, y_val\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f1e83e1",
      "metadata": {
        "id": "2f1e83e1"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Predict using Euclidean distance from training samples\n",
        "def predict_by_euclidean(df, n_realizations=10, normalize=False):\n",
        "    classes = df['label'].factorize()[1].to_list()\n",
        "    CM_aver = np.zeros((len(classes), len(classes)))\n",
        "    for _ in range(n_realizations):\n",
        "        _, y, X_train, X_test, y_train, y_test = get_X_y_train(df, normalization=normalize)\n",
        "        cm = np.zeros_like(CM_aver)\n",
        "        for i, x_test in enumerate(X_test):\n",
        "            distances = np.linalg.norm(X_train - x_test, axis=1)\n",
        "            y_pred = y_train[np.argmin(distances)]\n",
        "            cm[y_test[i], y_pred] += 1\n",
        "        cm = cm / cm.sum(axis=1, keepdims=True)\n",
        "        CM_aver += cm\n",
        "    CM_aver /= n_realizations\n",
        "    acc = round(np.mean(np.diag(CM_aver)), 2)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=CM_aver)\n",
        "    disp.plot()\n",
        "    disp.ax_.set_title(f\"Euclidean Distance | Acc: {acc}\")\n",
        "    plt.xticks(ticks=np.arange(len(classes)), labels=classes, rotation=45)\n",
        "    plt.yticks(ticks=np.arange(len(classes)), labels=classes, rotation=45)\n",
        "    plt.gcf().set_size_inches(10, 10)\n",
        "    return CM_aver, acc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Run model"
      ],
      "metadata": {
        "id": "7pQp6OEtRfM2"
      },
      "id": "7pQp6OEtRfM2"
    },
    {
      "cell_type": "code",
      "source": [
        "# Example run for orginal dataset\n",
        "df_embed = make_embedding(df_orginal, herbert_klej)\n",
        "df_embed['label'] = df_embed['label'].astype(str)  # Ensure consistency\n",
        "df_embed = df_embed.reset_index(drop=True)\n",
        "\n",
        "cm, acc = predict_by_euclidean(df_embed, normalize=False)\n",
        "print(\"Average accuracy:\", acc)\n"
      ],
      "metadata": {
        "id": "yhE-g5z6RkWb"
      },
      "id": "yhE-g5z6RkWb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example run for women dataset\n",
        "df_embed_women = make_embedding(df_women, herbert_klej)\n",
        "df_embed_women['label'] = df_embed_women['label'].astype(str)  # Ensure consistency\n",
        "df_embed_women = df_embed_women.reset_index(drop=True)\n",
        "\n",
        "cm_women, acc_women = predict_by_euclidean(df_embed_women, normalize=False)\n",
        "print(\"Average accuracy (women):\", acc_women)\n"
      ],
      "metadata": {
        "id": "NJnsqzqZRkn1"
      },
      "id": "NJnsqzqZRkn1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2eea8ad7",
      "metadata": {
        "id": "2eea8ad7"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Example run for men dataset\n",
        "df_embed_men = make_embedding(df_men, herbert_klej)\n",
        "df_embed_men['label'] = df_embed_men['label'].astype(str)  # Ensure consistency\n",
        "df_embed_men = df_embed_men.reset_index(drop=True)\n",
        "\n",
        "cm_men, acc_men = predict_by_euclidean(df_embed_men, normalize=False)\n",
        "print(\"Average accuracy (men):\", acc_men)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
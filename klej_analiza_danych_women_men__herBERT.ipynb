{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_17sa8j9Cg4"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install sacremoses"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q scanpy\n",
        "!pip install -q leidenalg"
      ],
      "metadata": {
        "id": "1rPhT-Q3Hss9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall numba\n",
        "!pip install -q umap-learn==0.5.1\n",
        "!pip install -U numba\n",
        "#!pip install -e git+https://github.com/lmcinnes/umap.git@0.4dev#egg=umap4\n",
        "#!pip install /content/src/umap4"
      ],
      "metadata": {
        "id": "41ApK9nDFyra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLM5dKam9Vo6"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import cross_val_score, train_test_split\n",
        "import joblib\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from transformers import HerbertTokenizer, RobertaModel, AutoTokenizer, BertModel\n",
        "\n",
        "import umap\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YYBaBrbT9xTN"
      },
      "outputs": [],
      "source": [
        "def get_data_set(labels, df):\n",
        "  idxs = []\n",
        "  for label in labels:\n",
        "    idxs_for_label, = np.where(df['Label'] == label)\n",
        "    for idx in idxs_for_label:\n",
        "      idxs.append(idx)\n",
        "\n",
        "  new_df = df.iloc[idxs]\n",
        "  new_df = new_df.sample(frac = 1).reset_index(drop=True)\n",
        "  return new_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7MoiQjw-x5D"
      },
      "outputs": [],
      "source": [
        "def print_classes(df):\n",
        "  y = df[\"Label\"]\n",
        "  #jeśli jest mniej niż 8 klas:\n",
        "  if len(df['Label'].unique()) < 8:\n",
        "    y = df ['Label'].factorize()[0]\n",
        "  authors = {}\n",
        "  num_classes = len(df['Label'].unique())\n",
        "  for label in range(0, num_classes):\n",
        "    i, = np.where(y == label)\n",
        "    authors['{}'.format(df['Author-short'][i[0]])] = label\n",
        "\n",
        "  return authors"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_tokens(df, model):\n",
        "  model_name, tokenizer, model = model\n",
        "  tokens = {}\n",
        "\n",
        "  df_tokens = pd.DataFrame()\n",
        "  tokenize = lambda sent: tokenizer.encode_plus(sent, max_length=512, padding='max_length', truncation=True)\n",
        "  df_tokens['tokens'] = df['Text'].map(tokenize)\n",
        "  df_tokens['input_ids'] = df_tokens['tokens'].map(lambda t: t['input_ids'] )\n",
        "  df_tokens['token_type_ids'] = df_tokens['tokens'].map(lambda t: t['token_type_ids'] )\n",
        "  df_tokens['attention_mask'] = df_tokens['tokens'].map(lambda t: t['attention_mask'] )\n",
        "\n",
        "\n",
        "  input_ids = np.stack(df_tokens['input_ids'])\n",
        "  token_type_ids = np.stack(df_tokens['token_type_ids'])\n",
        "  attention_mask = np.stack(df_tokens['attention_mask'])\n",
        "\n",
        "  inputs = {\"input_ids\":torch.tensor(input_ids),\"token_type_ids\":torch.tensor(token_type_ids),\"attention_mask\":torch.tensor(attention_mask)}\n",
        "\n",
        "  return df_tokens, inputs\n"
      ],
      "metadata": {
        "id": "wCyrtBSswp27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_tokens, inputs = make_tokens(df_raw, herbert)"
      ],
      "metadata": {
        "id": "SksBWf7qz37H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model(**inputs)"
      ],
      "metadata": {
        "id": "S5cqibv0Jsuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dzielenie tokenów na 9 porcji\n",
        "X_stack = []\n",
        "embedded = {}\n",
        "model_name, tokenizer, model = herbert\n",
        "\n",
        "for idx in tqdm(range(0,400)):\n",
        "  x = 0\n",
        "\n",
        "  for i in range(0,9):\n",
        "\n",
        "    y = x+100\n",
        "    if(i>7):\n",
        "      y = 512\n",
        "\n",
        "    input_ids = np.stack(df_tokens[\"input_ids\"].iloc[idx:idx+1])\n",
        "    token_type_ids = np.stack(df_tokens[\"token_type_ids\"].iloc[idx:idx+1])\n",
        "    attention_mask = np.stack(df_tokens[\"attention_mask\"].loc[idx:idx+1])\n",
        "\n",
        "    input_ids = np.array([input_ids[0][x:y]])\n",
        "    token_type_ids = np.array([token_type_ids[0][x:y]])\n",
        "    attention_mask = np.array([attention_mask[0][x:y]])\n",
        "\n",
        "    x = x + 60\n",
        "\n",
        "    inputs = {\"input_ids\":torch.tensor(input_ids),\"token_type_ids\":torch.tensor(token_type_ids),\"attention_mask\":torch.tensor(attention_mask)}\n",
        "\n",
        "    single_poem_output = model(**inputs)\n",
        "    X_single_poem = single_poem_output[0][:,0,:].detach().numpy()\n",
        "    X_stack.append(X_single_poem[0])\n",
        "    embedded[idx,i] = X_single_poem[0], df_raw['Label'][idx]\n",
        "\n",
        "\n",
        "  df_embedded = pd.DataFrame.from_dict(embedded,  orient='index', columns=['embedding', 'label'])\n",
        "\n"
      ],
      "metadata": {
        "id": "h_CqPX27BleG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rcxPj1XC98Y5"
      },
      "outputs": [],
      "source": [
        "def make_embedding(df, model):\n",
        "\n",
        "  X_stack = []\n",
        "  model_name, tokenizer, model = model\n",
        "  embedded = {}\n",
        "  tokens = {}\n",
        "  num_idxs = df.shape[0]\n",
        "  for idx in tqdm(range(0,num_idxs)):\n",
        "    single_poem_input = df['Text'][idx]\n",
        "    inputs = tokenizer.batch_encode_plus([single_poem_input], max_length = 512, padding=\"longest\", add_special_tokens=True, return_tensors=\"pt\",)\n",
        "    single_poem_output = model(**inputs)\n",
        "    X_single_poem = single_poem_output[0][:,0,:].detach().numpy()\n",
        "    X_stack.append(X_single_poem[0])\n",
        "\n",
        "    embedded[idx] = X_single_poem[0], df['Label'][idx]\n",
        "\n",
        "  df_embedded = pd.DataFrame.from_dict(embedded,  orient='index', columns=['embedding', 'label'])\n",
        "\n",
        "  return df_embedded"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_X_y(df):\n",
        "\n",
        "  X = np.stack(df['embedding'])\n",
        "  y = df['Label']\n",
        "\n",
        "  #jeśli jest mniej niż 8 klas:\n",
        "  if len(df['Label'].unique()) < 8:\n",
        "    y = df ['Label'].factorize()[0]\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "  X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
        "\n",
        "  print(X.shape)\n",
        "\n",
        "  return X, y, X_train, X_test, y_train, y_test,  X_val, y_val"
      ],
      "metadata": {
        "id": "vBgmJ_f_FFbO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_data(X):\n",
        "\n",
        "  X_normalized = np.zeros((X.shape[0],X.shape[1]))\n",
        "\n",
        "  for idx in range(0,X.shape[0]):\n",
        "    X_normalized[idx,:] = (X[idx,:] - np.mean(X[idx,:]))/ np.std(X[idx,:])\n",
        "\n",
        "  return X_normalized"
      ],
      "metadata": {
        "id": "DuSBYI_0h106"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3oYyP5gm9uGe"
      },
      "outputs": [],
      "source": [
        "herbert_large = [\"Herbert-large\", HerbertTokenizer.from_pretrained(\"allegro/herbert-large-cased\"), RobertaModel.from_pretrained(\"allegro/herbert-large-cased\")]\n",
        "herbert_base = [\"Herbert-base\", HerbertTokenizer.from_pretrained(\"allegro/herbert-base-cased\"), RobertaModel.from_pretrained(\"allegro/herbert-base-cased\")]\n",
        "herbert_klej = [\"Herbert-klej\", HerbertTokenizer.from_pretrained(\"allegro/herbert-klej-cased-tokenizer-v1\"), RobertaModel.from_pretrained(\"allegro/herbert-klej-cased-v1\")]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_EyIJ1K9kuf"
      },
      "outputs": [],
      "source": [
        "df_raw = pd.read_csv('/content/wiersze_do_BERT_Herbert_Miłosz.csv', \";\")\n",
        "df_raw .columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_TUR0Zj9s3Y"
      },
      "outputs": [],
      "source": [
        "df_raw  = df_raw .drop(columns = ['Unnamed: 9', 'Unnamed: 10', 'Unnamed: 11'])\n",
        "df_raw.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_raw = df_raw.drop(df_raw.index[400:])\n",
        "df_raw"
      ],
      "metadata": {
        "id": "CTGUHH6NJd7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_orginal = pd.DataFrame\n",
        "df_orginal = pd.concat([df_raw['Text'],df_raw['Label'],df_raw['Author-short']], axis=1)"
      ],
      "metadata": {
        "id": "XX43L8Oy8xm3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_orginal"
      ],
      "metadata": {
        "id": "uCWpyR6v9PCX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sjKN6rdn9sn3"
      },
      "outputs": [],
      "source": [
        "df_women = df_raw[200:].reset_index(drop=True)\n",
        "df_men = df_raw[:200].reset_index(drop=True)\n",
        "#df_women = df_women.sample(frac = 1).reset_index(drop=True)\n",
        "#df_men = df_men.sample(frac = 1).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_men = make_embedding(df_men, herbert_klej)\n",
        "df_men = pd.concat([df_men, embedding_men['embedding']], axis=1)\n",
        "df_men"
      ],
      "metadata": {
        "id": "yZ7v7okgBwcH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_women = make_embedding(df_women, herbert_klej)\n",
        "df_women = pd.concat([df_women, embedding_women['embedding']], axis=1)\n",
        "df_women"
      ],
      "metadata": {
        "id": "AahEKj0WIwmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = print_classes(df_women)\n",
        "classes"
      ],
      "metadata": {
        "id": "QYCINTOqJKZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y, _,_,_,_,_,_ = get_X_y(df_women)"
      ],
      "metadata": {
        "id": "moPokgr2J3AT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_norm = normalize_data(X)"
      ],
      "metadata": {
        "id": "PYLkXuJSqG0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Umap\n",
        "df_umap = pd.DataFrame()\n",
        "df_umap[\"y\"] = df_women['Author-short']\n",
        "data_type = 'women'\n",
        "num_classes = len(classes)\n",
        "n_neighbors = [20]\n",
        "min_distnces= [0.05]\n",
        "n_components=2\n",
        "metric='euclidean'\n",
        "\n",
        "for n_neighbor in n_neighbors:\n",
        "  for min_dist in min_distnces:\n",
        "    reducer = umap.UMAP(n_neighbors=n_neighbor,\n",
        "            min_dist=min_dist,\n",
        "            n_components=n_components,\n",
        "            metric=metric)\n",
        "    scaled_X = StandardScaler().fit_transform(X)\n",
        "    embed = reducer.fit_transform(scaled_X)\n",
        "\n",
        "    df_umap[\"comp-1\"] = embed[:,0]\n",
        "    df_umap[\"comp-2\"] = embed[:,1]\n",
        "\n",
        "    plt.figure(figsize = (10,10))\n",
        "    sns.scatterplot(x=\"comp-1\", y=\"comp-2\", hue=df_umap.y.tolist(),\n",
        "                   palette=sns.color_palette(\"Set2\", num_classes),\n",
        "                   data=df_umap, s=100).set(title=\"Poems data Umap projection | Data type: {} | N_neighbors: {} | Distance: {}\".format(data_type, n_neighbor, min_dist))\n",
        "\n",
        "\n",
        "plt.savefig('/content/figs/umap_{}.png'.format(data_type))\n",
        "#files.download('/content/figs/umap_{}.png'.format(data_type))"
      ],
      "metadata": {
        "id": "16AVZy-nIuPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3D Umap\n",
        "data_type = 'women'\n",
        "num_classes = len(classes)\n",
        "n_neighbors = [20]\n",
        "min_distnces= [0.05]\n",
        "n_components=3\n",
        "metric='euclidean'\n",
        "for n_neighbor in n_neighbors:\n",
        "  for min_dist in min_distnces:\n",
        "    reducer = umap.UMAP(n_neighbors=n_neighbor,\n",
        "                min_dist=min_dist,\n",
        "                n_components=n_components,\n",
        "                metric=metric)\n",
        "    scaled_X = StandardScaler().fit_transform(X)\n",
        "    embed = reducer.fit_transform(scaled_X)\n",
        "\n",
        "    Xax = embed[:,0]\n",
        "    Yax = embed[:,1]\n",
        "    Zax = embed[:, 2]\n",
        "\n"
      ],
      "metadata": {
        "id": "82WCj0F7KE6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cdict = {0:'cyan',1:'red',2:'blue',3:'green',4:'yellow',5:'violet',6:'orange',7:'brown'}\n",
        "cdict = {0:'yellow',1:'violet',2:'orange',3:'brown'}\n",
        "#label = {0:'J. Kochanowki',1:'K. K. Baczyński',2:'Cz. Miłosz',3:'Z. Herbert'}\n",
        "label = {0:'W. Szymborska',1:'H. Poświatowska',2:'M. P. Jasnorzewska',3:'E. Lipska'}\n",
        "\n",
        "fig = plt.figure(figsize=(14,9))\n",
        "ax = fig.add_subplot(111,\n",
        "                    projection='3d')\n",
        "\n",
        "for l in np.unique(y):\n",
        "  ix=np.where(y==l)\n",
        "  ax.scatter(Xax[ix],\n",
        "              Yax[ix],\n",
        "              Zax[ix],\n",
        "              c=cdict[l],\n",
        "              s=60,\n",
        "            label=label[l])\n",
        "\n",
        "ax.set_xlabel(\"PC1\",\n",
        "              fontsize=12)\n",
        "ax.set_ylabel(\"PC2\",\n",
        "              fontsize=12)\n",
        "ax.set_zlabel(\"PC3\",\n",
        "              fontsize=12)\n",
        "\n",
        "ax.view_init(200, 160)\n",
        "ax.legend()\n",
        "plt.title(\"Poems data 3D Umap projection | Data type: {}\".format(data_type))\n",
        "plt.show()\n",
        "\n",
        "fig.savefig('/content/figs/umap_3D_{}.png'.format(data_type))\n",
        "files.download('/content/figs/umap_3D_{}.png'.format(data_type))"
      ],
      "metadata": {
        "id": "LTH_f-uoL8dC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3D PCA\n",
        "data_type = 'women'\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X)\n",
        "scaled_X = scaler.transform(X)\n",
        "pca = PCA(n_components=3)\n",
        "pca.fit(scaled_X)\n",
        "pca_X = pca.transform(scaled_X)"
      ],
      "metadata": {
        "id": "cElpqKjBTpoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "angle1 = 5\n",
        "\n",
        "angles = [290]# np.arange(100,175,5)\n",
        "for angle2 in angles:\n",
        "  Xax = pca_X[:,0]\n",
        "  Yax = pca_X[:,1]\n",
        "  Zax = pca_X[:,2]\n",
        "\n",
        "  #cdict = {0:'cyan',1:'red',2:'blue',3:'green',4:'yellow',5:'violet',6:'orange',7:'brown'}\n",
        "  cdict = {0:'yellow',1:'violet',2:'orange',3:'brown'}\n",
        "  #label = {0:'J. Kochanowki',1:'K. K. Baczyński',2:'Cz. Miłosz',3:'Z. Herbert'}\n",
        "  label = {0:'W. Szymborska',1:'H. Poświatowska',2:'M. P. Jasnorzewska',3:'E. Lipska'}\n",
        "\n",
        "  fig = plt.figure(figsize=(14,9))\n",
        "  ax = fig.add_subplot(111,\n",
        "                     projection='3d')\n",
        "\n",
        "  for l in np.unique(y):\n",
        "    ix=np.where(y==l)\n",
        "    ax.scatter(Xax[ix],\n",
        "              Yax[ix],\n",
        "              Zax[ix],\n",
        "              c=cdict[l],\n",
        "              s=60,\n",
        "            label=label[l])\n",
        "\n",
        "  ax.set_xlabel(\"PC1\",\n",
        "                fontsize=12)\n",
        "  ax.set_ylabel(\"PC2\",\n",
        "                fontsize=12)\n",
        "  ax.set_zlabel(\"PC3\",\n",
        "                fontsize=12)\n",
        "\n",
        "  ax.view_init(60, 130)\n",
        "  ax.legend()\n",
        "  plt.title(\"Poems data 3D PCA projection | Data type: {} \".format(data_type))\n",
        "  plt.show()\n",
        "\n",
        "fig.savefig('/content/figs/pca_3D_{}.png'.format(data_type))\n",
        "files.download('/content/figs/pca_3D_{}.png'.format(data_type))"
      ],
      "metadata": {
        "id": "BR_9d--PNrF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pca = pd.DataFrame()\n",
        "df_pca[\"y\"] = df_women['Author-short']\n",
        "data_type = 'women'\n",
        "num_classes = len(classes)\n",
        "\n",
        "plt.figure(figsize = (10,10))\n",
        "pca = PCA(n_components=2).fit_transform(X, y)\n",
        "\n",
        "df_pca[\"comp-1\"] = pca[:,0]\n",
        "df_pca[\"comp-2\"] = pca[:,1]\n",
        "\n",
        "sns.scatterplot(x=\"comp-1\", y=\"comp-2\", hue=df_pca.y.tolist(),\n",
        "                palette=sns.color_palette(\"Set2\", num_classes),\n",
        "                data=df_pca, s=100).set(title=\"Poems data PCA projection | Data type: {}\".format(data_type))\n",
        "\n",
        "plt.savefig('/content/figs/pca_{}.png'.format(data_type))\n",
        "files.download('/content/figs/pca_{}.png'.format(data_type))"
      ],
      "metadata": {
        "id": "a1SNCcFe38X-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_tsne = pd.DataFrame()\n",
        "df_tsne[\"y\"] = df_women['Author-short']\n",
        "data_type = 'women'\n",
        "num_classes = len(classes)\n",
        "\n",
        "perps = [45]\n",
        "\n",
        "for perp in perps:\n",
        "\n",
        "  plt.figure(figsize = (10,10))\n",
        "  z = TSNE(n_components=2, learning_rate='auto', init='pca', perplexity=perp).fit_transform(X, y)\n",
        "\n",
        "  df_tsne[\"comp-1{}\".format(perp)] = z[:,0]\n",
        "  df_tsne[\"comp-2{}\".format(perp)] = z[:,1]\n",
        "\n",
        "  sns.scatterplot(x=\"comp-1{}\".format(perp), y=\"comp-2{}\".format(perp), hue=df_tsne.y.tolist(),\n",
        "                palette=sns.color_palette(\"Set2\", num_classes),\n",
        "                data=df_tsne, s=100).set(title=\"Poems data t-SNE projection | Perplexity: {} | Data type: {}\".format(perp, data_type))\n",
        "\n",
        "  plt.savefig('/content/figs/tsne_{}_{}_perplexity.png'.format(data_type, perp))\n",
        "  files.download('/content/figs/tsne_{}_{}_perplexity.png'.format(data_type, perp))"
      ],
      "metadata": {
        "id": "_gnNMGny4ANU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distance_euclidean_X_normalized = np.zeros((X_norm.shape[0], X_norm.shape[0]))\n",
        "distance_cosinus_X_normalized = np.zeros((X_norm.shape[0], X_norm.shape[0]))\n",
        "\n",
        "for i in range(0,distance_euclidean_X_normalized.shape[0]):\n",
        "  x_normalized_i = X_norm[i,:]\n",
        "  for j in range(0,distance_euclidean_X_normalized.shape[0]):\n",
        "    x_normalized_j = X_norm[j,:]\n",
        "    distance_euclidean_X_normalized[i,j] = np.sqrt(np.sum( np.abs(x_normalized_i - x_normalized_j)**2))\n",
        "    distance_cosinus_X_normalized[i,j] = np.dot(x_normalized_i, x_normalized_j)/1024\n"
      ],
      "metadata": {
        "id": "tQK1GLJEV4JO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distances = {\"Euclidean distance\":distance_euclidean_X_normalized, \"Cosinus distance\":distance_cosinus_X_normalized}\n",
        "data_type = \"all\"\n",
        "fig, ax = plt.subplots(1,2, figsize=(20,10), sharey='row')\n",
        "im = ax[0].imshow(distance_euclidean_X_normalized)\n",
        "ax[0].set_title('Euclidean distance', fontsize=20)\n",
        "im2 = ax[1].imshow(distance_cosinus_X_normalized)\n",
        "ax[1].set_title('Cosinus distance', fontsize=20)\n",
        "fig.colorbar(im, ax=ax[0])\n",
        "fig.colorbar(im2, ax=ax[1])\n",
        "\n",
        "fig.savefig('/content/figs/euclidean_and_cosinus.png')\n",
        "files.download('/content/figs/euclidean_and_cosinus.png')\n"
      ],
      "metadata": {
        "id": "bOt8DITYYPBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "M_men = np.zeros((200,200))\n",
        "\n",
        "for i in range(0,200):\n",
        "  x_i = embedded_men['Herbert_embedding'][i]\n",
        "  for j in range(0,200):\n",
        "    x_j = embedded_men['Herbert_embedding'][j]\n",
        "\n",
        "    #scalar_product = np.dot(x_i, x_j)\n",
        "    #M[i,j] = scalar_product\n",
        "    M_men[i,j] = np.sqrt(np.sum( np.abs(x_i - x_j)**2))\n",
        "plt.imshow(M_men)\n",
        "plt.colorbar()\n",
        "plt.title('Distance between vectors | data type: men')\n",
        "\n",
        "\n",
        "plt.savefig('/content/odległość_wektorów_po_ombeddingu_men.png')\n",
        "files.download('/content/odległość_wektorów_po_ombeddingu_men.png')"
      ],
      "metadata": {
        "id": "HSh5745ndWUL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "1sXz1c0udWOaxJgXJJk1p94EQBJ1YCS5V",
      "authorship_tag": "ABX9TyOea96ThLPP3oDHEE3UuzIA"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}